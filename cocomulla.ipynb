{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load....musicgen bk\n",
      "lm_bk, here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLIPPING /l/users/fathinah.izzati/coco-mulla-repo/demo/output/chord-only happening with proba (a bit of clipping is okay): 0.00012656250328291208 maximum scale:  1.2986297607421875\n",
      "CLIPPING /l/users/fathinah.izzati/coco-mulla-repo/demo/output/chord-drums happening with proba (a bit of clipping is okay): 7.812499825377017e-05 maximum scale:  1.1229928731918335\n",
      "CLIPPING /l/users/fathinah.izzati/coco-mulla-repo/demo/output/chord-midi happening with proba (a bit of clipping is okay): 3.12499992105586e-06 maximum scale:  1.0149791240692139\n",
      "CLIPPING /l/users/fathinah.izzati/coco-mulla-repo/demo/output/chord-drums-midi happening with proba (a bit of clipping is okay): 4.687500222644303e-06 maximum scale:  1.1103787422180176\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import librosa\n",
    "\n",
    "from coco_mulla.models import CoCoMulla\n",
    "from coco_mulla.utilities import *\n",
    "from coco_mulla.utilities.encodec_utils import extract_rvq, save_rvq\n",
    "from coco_mulla.utilities.symbolic_utils import process_midi, process_chord\n",
    "\n",
    "from coco_mulla.utilities.sep_utils import separate\n",
    "from config import TrainCfg\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "def generate(model_path, batch):\n",
    "    model = CoCoMulla(TrainCfg.sample_sec,\n",
    "                      num_layers=args.num_layers,\n",
    "                      latent_dim=args.latent_dim).to(device)\n",
    "    model.load_weights(model_path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        gen_tokens = model(**batch)\n",
    "\n",
    "    return gen_tokens\n",
    "\n",
    "\n",
    "def generate_mask(xlen):\n",
    "    names = [\"chord-only\", \"chord-drums\", \"chord-midi\", \"chord-drums-midi\"]\n",
    "    mask = torch.zeros([4, 2, xlen]).to(device)\n",
    "    mask[1, 1] = 1\n",
    "    mask[2, 0] = 1\n",
    "    mask[3] += 1\n",
    "    return mask, names\n",
    "\n",
    "\n",
    "def load_data(audio_path, chord_path, midi_path, offset):\n",
    "    sr = TrainCfg.sample_rate\n",
    "    res = TrainCfg.frame_res\n",
    "    sample_sec = TrainCfg.sample_sec\n",
    "\n",
    "    wav, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    wav = np2torch(wav).to(device)[None, None, ...]\n",
    "    wavs = separate(wav, sr)\n",
    "    drums_rvq = extract_rvq(wavs[\"drums\"], sr=sr)\n",
    "    chord, _ = process_chord(chord_path)\n",
    "    flatten_midi_path = midi_path + \".piano.mid\"\n",
    "    midi, _ = process_midi(midi_path)\n",
    "\n",
    "\n",
    "\n",
    "    chord = crop(chord[None, ...], \"chord\", sample_sec, res)\n",
    "    pad_chord = chord.sum(-1, keepdims=True) == 0\n",
    "    chord = np.concatenate([chord, pad_chord], -1)\n",
    "\n",
    "    midi = crop(midi[None, ...], \"midi\", sample_sec, res,offset=offset)\n",
    "    drums_rvq = crop(drums_rvq[None, ...], \"drums_rvq\", sample_sec, res, offset=offset)\n",
    "\n",
    "    chord = torch.from_numpy(chord).to(device).float()\n",
    "    midi = torch.from_numpy(midi).to(device).float()\n",
    "    drums_rvq = drums_rvq.to(device).long()\n",
    "\n",
    "    return drums_rvq, midi, chord\n",
    "\n",
    "\n",
    "def crop(x, mode, sample_sec, res, offset=0):\n",
    "    xlen = x.shape[1] if mode == \"chord\" or mode == \"midi\" else x.shape[-1]\n",
    "    sample_len = int(sample_sec * res) + 1\n",
    "    if xlen < sample_len:\n",
    "        if mode == \"chord\" or mode == \"midi\":\n",
    "            x = np.pad(x, ((0, 0), (0, sample_len - xlen), (0, 0)))\n",
    "        else:\n",
    "            x = F.pad(x, (0, sample_len - xlen), \"constant\", 0)\n",
    "        return x\n",
    "\n",
    "    st = offset * res\n",
    "    ed = int((offset + sample_sec) * res) + 1\n",
    "    if mode == \"chord\" or mode == \"midi\":\n",
    "        assert x.shape[1] > st\n",
    "        return x[:, st: ed]\n",
    "    assert x.shape[2] > ed\n",
    "    return x[:, :, st: ed]\n",
    "\n",
    "\n",
    "def save_pred(output_folder, tags, pred):\n",
    "    mkdir(output_folder)\n",
    "    output_list = [os.path.join(output_folder, tag) for tag in tags]\n",
    "    save_rvq(output_list=output_list, tokens=pred)\n",
    "\n",
    "\n",
    "def wrap_batch(drums_rvq, midi, chord, cond_mask, prompt):\n",
    "    num_samples = len(cond_mask)\n",
    "    midi = midi.repeat(num_samples, 1, 1)\n",
    "    chord = chord.repeat(num_samples, 1, 1)\n",
    "    drums_rvq = drums_rvq.repeat(num_samples, 1, 1)\n",
    "    prompt = [prompt] * num_samples\n",
    "    batch = {\n",
    "        \"seq\": None,\n",
    "        \"desc\": prompt,\n",
    "        \"chords\": chord,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"cond_mask\": cond_mask,\n",
    "        \"drums\": drums_rvq,\n",
    "        \"piano_roll\": midi,\n",
    "        \"mode\": \"inference\",\n",
    "    }\n",
    "    return batch\n",
    "\n",
    "\n",
    "def inference(args):\n",
    "    drums_rvq, midi, chord = load_data(audio_path=args.audio_path,\n",
    "                                       chord_path=args.chord_path,\n",
    "                                       midi_path=args.midi_path,\n",
    "                                       offset=args.offset)\n",
    "    cond_mask, names = generate_mask(drums_rvq.shape[-1])\n",
    "    batch = wrap_batch(drums_rvq, midi, chord, cond_mask, read_lst(args.prompt_path)[0])\n",
    "    pred = generate(model_path=args.model_path,\n",
    "                    batch=batch)\n",
    "    save_pred(output_folder=args.output_folder,\n",
    "              tags=names,\n",
    "              pred=pred)\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = {\n",
    "    \"num_layers\": 48,\n",
    "    \"latent_dim\": 12,\n",
    "    \"output_folder\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/output\",\n",
    "    \"model_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/diff_9_end.pth\",\n",
    "    \"audio_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.flac\",\n",
    "    \"prompt_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.prompt.txt\",\n",
    "    \"chord_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.flac.chord.lab\",\n",
    "    \"midi_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.mid.piano.mid\",\n",
    "    \"drums_path\": None,\n",
    "    \"offset\": 0\n",
    "}\n",
    "args = SimpleNamespace(**args)\n",
    "drums_rvq, midi, chord = load_data(audio_path=args.audio_path,\n",
    "                                    chord_path=args.chord_path,\n",
    "                                    midi_path=args.midi_path,\n",
    "                                    offset=args.offset)\n",
    "cond_mask, names = generate_mask(drums_rvq.shape[-1])\n",
    "batch = wrap_batch(drums_rvq, midi, chord, cond_mask, read_lst(args.prompt_path)[0])\n",
    "pred = inference(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.multiprocessing import spawn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from coco_mulla.utilities.trainer_utils import Trainer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from config import TrainCfg\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from coco_mulla.data_loader.dataset_sampler import Dataset, collate_fn\n",
    "from coco_mulla.models import CoCoMulla\n",
    "\n",
    "device = \"cuda\"\n",
    "N_GPUS = 1\n",
    "\n",
    "\n",
    "def _get_free_port():\n",
    "    import socketserver\n",
    "    with socketserver.TCPServer(('localhost', 0), None) as s:\n",
    "        return s.server_address[1]\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(dataset_split, sampling_strategy, sampling_prob):\n",
    "\n",
    "    file_lst = [\"data/text/musdb18_full.lst\",\n",
    "                \"data/text/closed_dataset_fm_full.lst\"]\n",
    "    splits = [\n",
    "        [1],\n",
    "        [0],\n",
    "        [0, 1],\n",
    "    ]\n",
    "    dataset = Dataset(\n",
    "        rid=0, # No distributed rank needed\n",
    "        path_lst=[dataset_split],\n",
    "        sampling_prob=sampling_prob,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        cfg=TrainCfg)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=TrainCfg.batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        # sampler=DistributedSampler(dataset),\n",
    "        pin_memory=True,\n",
    "        drop_last=True)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def train_dist(replica_id, replica_count, port, model_dir, args):\n",
    "    print('masuk sini')\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = str(port)\n",
    "    torch.distributed.init_process_group('nccl', rank=replica_id, world_size=replica_count)\n",
    "    device = torch.device('cuda', replica_id)\n",
    "    print(device)\n",
    "    torch.cuda.set_device(device)\n",
    "    model = CoCoMulla(TrainCfg.sample_sec, num_layers=args.num_layers, latent_dim=args.latent_dim).to(device)\n",
    "    model.set_training()\n",
    "    model = DDP(model, [replica_id])\n",
    "    dataset, dataloader = get_dataset(rid=replica_id, dataset_split=args.dataset,\n",
    "                                      sampling_strategy=args.sampling_strategy,\n",
    "                                      sampling_prob=[args.sampling_prob_a, args.sampling_prob_b])\n",
    "\n",
    "    # train(replica_id, model, dataset, dataloader, device, model_dir,\n",
    "    #       args.learning_rate)\n",
    "\n",
    "\n",
    "def loss_fn(outputs, y):\n",
    "    prob = outputs.logits\n",
    "    mask = outputs.mask\n",
    "    prob = prob[mask]\n",
    "    y = y[mask]\n",
    "    prob = prob.view(-1, 2048)\n",
    "    return nn.CrossEntropyLoss()(prob, y)\n",
    "\n",
    "\n",
    "def train(model, dataset, dataloader, device, model_dir, learning_rate):\n",
    "    # optimizer and lr scheduler\n",
    "    num_steps = len(dataloader)\n",
    "    epochs = TrainCfg.epoch\n",
    "    rng = np.random.RandomState(569)\n",
    "    writer = SummaryWriter(model_dir, flush_secs=20)\n",
    "\n",
    "    trainer = Trainer(params=model.parameters(), lr=learning_rate, num_epochs=epochs, num_steps=num_steps)\n",
    "\n",
    "    model = model.to(device)\n",
    "    step = 0\n",
    "    for e in range(0, epochs):\n",
    "        mean_loss = 0\n",
    "        n_element = 0\n",
    "        model.train()\n",
    "\n",
    "        dl = tqdm(dataloader, desc=f\"Epoch {e}\")\n",
    "        r = rng.randint(0, 233333)\n",
    "        dataset.reset_random_seed(r, e)\n",
    "        for i, batch in enumerate(dl):\n",
    "            desc = batch[\"desc\"]\n",
    "            mix = batch[\"mix\"].to(device).long()\n",
    "            drums = batch[\"drums\"].to(device).long()\n",
    "            chords = batch[\"chords\"].to(device).float()\n",
    "            piano_roll = batch[\"piano_roll\"].to(device).float()\n",
    "            cond_mask = batch[\"cond_mask\"].to(device).long()\n",
    "\n",
    "            batch_1 = {\n",
    "                \"seq\": mix,\n",
    "                \"drums\": drums,\n",
    "                \"chords\": chords,\n",
    "                \"piano_roll\": piano_roll,\n",
    "                \"cond_mask\": cond_mask,\n",
    "                \"desc\": desc,\n",
    "\n",
    "            }\n",
    "            # with autocast:\n",
    "            outputs = model(**batch_1)\n",
    "            r_loss = loss_fn(outputs, mix.long())\n",
    "\n",
    "            grad_1, lr_1 = trainer.step(r_loss, model.parameters())\n",
    "\n",
    "            step += 1\n",
    "            n_element += 1\n",
    "            writer.add_scalar(\"r_loss\", r_loss.item(), step)\n",
    "            writer.add_scalar(\"grad_1\", grad_1, step)\n",
    "            writer.add_scalar(\"lr_1\", lr_1, step)\n",
    "\n",
    "            mean_loss += r_loss.item()\n",
    "\n",
    "        mean_loss = mean_loss / n_element\n",
    "        with torch.no_grad():\n",
    "            writer.add_scalar('train/mean_loss', mean_loss, step)\n",
    "            model.save_weights(os.path.join(model_dir, f\"diff_{e}_end.pth\"))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    experiment_folder = args.experiment_folder\n",
    "    experiment_name = args.experiment_name\n",
    "\n",
    "    if not os.path.exists(experiment_folder):\n",
    "        os.mkdir(experiment_folder)\n",
    "    model_dir = os.path.join(experiment_folder, experiment_name)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    world_size = N_GPUS\n",
    "    port = _get_free_port()\n",
    "    spawn(train_dist, args=(world_size, port, model_dir, args), nprocs=world_size, join=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masuk\n",
      "masuk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/l/users/fathinah.izzati/coco-mulla-repo/train.py\", line 68, in train_dist\n    torch.cuda.set_device(device)\n  File \"/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 404, in set_device\n    torch._C._cuda_setDevice(device)\nRuntimeError: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m      5\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m args \u001b[38;5;241m=\u001b[39m SimpleNamespace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 158\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    156\u001b[0m world_size \u001b[38;5;241m=\u001b[39m N_GPUS\n\u001b[1;32m    157\u001b[0m port \u001b[38;5;241m=\u001b[39m _get_free_port()\n\u001b[0;32m--> 158\u001b[0m \u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:246\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    240\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:202\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:163\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    161\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    162\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/l/users/fathinah.izzati/coco-mulla-repo/train.py\", line 68, in train_dist\n    torch.cuda.set_device(device)\n  File \"/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 404, in set_device\n    torch._C._cuda_setDevice(device)\nRuntimeError: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from train import train_dist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = {\n",
    "    \"num_layers\": 48,\n",
    "    \"latent_dim\": 12,\n",
    "    \"experiment_folder\": \"/l/users/fathinah.izzati/coco-mulla-repo/expe\",\n",
    "    \"experiment_name\": \"experiment_1\",\n",
    "    \"prompt_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.prompt.txt\",\n",
    "    'sampling_strategy':'prob-based',\n",
    "    \"dataset\": 0,\n",
    "    'learning_rate':0.1,\n",
    "    'sampling_prob_a':0.2,\n",
    "    'sampling_prob_b':0.8\n",
    "\n",
    "    }\n",
    "    args = SimpleNamespace(**args)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/96 [00:00<?, ?it/s]/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch 0: 100%|██████████| 96/96 [01:08<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    " from types import SimpleNamespace\n",
    "args = {\n",
    "    \"num_layers\": 48,\n",
    "    \"latent_dim\": 12,\n",
    "    \"experiment_folder\": \"/l/users/fathinah.izzati/coco-mulla-repo/expe\",\n",
    "    \"experiment_name\": \"experiment_1\",\n",
    "    \"prompt_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.prompt.txt\",\n",
    "    'sampling_strategy':'prob-based',\n",
    "    \"dataset\": '/l/users/fathinah.izzati/coco-mulla-repo/train.lst',\n",
    "    'learning_rate':0.1\n",
    "\n",
    "}\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "experiment_folder = args.experiment_folder\n",
    "experiment_name = args.experiment_name\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.mkdir(experiment_folder)\n",
    "model_dir = os.path.join(experiment_folder, experiment_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    " dataset, dataloader = get_dataset(\n",
    "        dataset_split=args.dataset,\n",
    "        sampling_strategy=args.sampling_strategy,\n",
    "        sampling_prob=None\n",
    "    )\n",
    "model = CoCoMulla(TrainCfg.sample_sec, num_layers=args.num_layers, latent_dim=args.latent_dim).to(device)\n",
    "model.set_training()\n",
    "train(model, dataset, dataloader, device, model_dir, args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Training adoption steps\n",
    "\n",
    "1. Change config\n",
    "2. Chage  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fathinah.izzati/miniconda3/envs/cocomulla/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.multiprocessing import spawn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from coco_mulla.utilities.trainer_utils import Trainer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from coco_mulla.models import CoCoMulla\n",
    "\n",
    "device = \"cuda\"\n",
    "N_GPUS = 4\n",
    "\n",
    "## fixed\n",
    "from coco_mulla.data_loader.dataset_sampler import Dataset, collate_fn\n",
    "from config import TrainCfg\n",
    "\n",
    "def _get_free_port():\n",
    "    import socketserver\n",
    "    with socketserver.TCPServer(('localhost', 0), None) as s:\n",
    "        return s.server_address[1]\n",
    "\n",
    "\n",
    "def get_dataset(rid, dataset_path, sampling_strategy, sampling_prob):\n",
    "\n",
    "    dataset = Dataset(\n",
    "        rid=rid,\n",
    "        path_lst=[dataset_path],\n",
    "        sampling_prob=sampling_prob,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        cfg=TrainCfg)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=TrainCfg.batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=True)\n",
    "\n",
    "    return dataset, dataloader\n",
    "def train_dist(replica_id, replica_count, port, model_dir, args):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = str(port)\n",
    "    torch.distributed.init_process_group('nccl', rank=replica_id, world_size=replica_count)\n",
    "    device = torch.device('cuda', replica_id)\n",
    "    torch.cuda.set_device(device)\n",
    "    model = CoCoMulla(TrainCfg.sample_sec, num_layers=args.num_layers, latent_dim=args.latent_dim).to(device)\n",
    "    model.set_training()\n",
    "    model = DDP(model, [replica_id])\n",
    "    dataset, dataloader = get_dataset(rid=replica_id, dataset_split=args.dataset,\n",
    "                                      sampling_strategy=args.sampling_strategy,\n",
    "                                      sampling_prob=[args.sampling_prob_a, args.sampling_prob_b])\n",
    "\n",
    "    train(replica_id, model, dataset, dataloader, device, model_dir,\n",
    "          args.learning_rate)\n",
    "\n",
    "\n",
    "def loss_fn(outputs, y):\n",
    "    prob = outputs.logits\n",
    "    mask = outputs.mask\n",
    "    prob = prob[mask]\n",
    "    y = y[mask]\n",
    "    prob = prob.view(-1, 2048)\n",
    "    return nn.CrossEntropyLoss()(prob, y)\n",
    "def train(rank, model, dataset, dataloader, device, model_dir, learning_rate):\n",
    "    # optimizer and lr scheduler\n",
    "    num_steps = len(dataloader)\n",
    "    epochs = TrainCfg.epoch\n",
    "    rng = np.random.RandomState(569 + rank * 100)\n",
    "    if rank == 0:\n",
    "        writer = SummaryWriter(model_dir, flush_secs=20)\n",
    "\n",
    "    trainer = Trainer(params=model.parameters(), lr=learning_rate, num_epochs=epochs, num_steps=num_steps)\n",
    "\n",
    "    model = model.to(device)\n",
    "    step = 0\n",
    "    for e in range(0, epochs):\n",
    "        mean_loss = 0\n",
    "        n_element = 0\n",
    "        model.train()\n",
    "\n",
    "        dl = tqdm(dataloader, desc=f\"Epoch {e}\") if rank == 0 else dataloader\n",
    "        r = rng.randint(0, 233333)\n",
    "        dataset.reset_random_seed(r, e)\n",
    "        for i, batch in enumerate(dl):\n",
    "            desc = batch[\"desc\"]\n",
    "            mix = batch[\"mix\"].to(device).long()\n",
    "            rgb_emb = batch[\"rgb_emb\"].to(device).long()\n",
    "            cond_mask = batch[\"cond_mask\"].to(device).long()\n",
    "\n",
    "            batch_1 = {\n",
    "                 \"seq\": mix,\n",
    "                \"rgb_emb\":rgb_emb,\n",
    "                \"cond_mask\": cond_mask,\n",
    "                \"desc\": desc,\n",
    "\n",
    "            }\n",
    "            print('seq',batch_1['seq'].shape)\n",
    "            print('rgb_emb',batch_1['rgb_emb'].shape)\n",
    "            print('cond_mask',batch_1['cond_mask'].shape)\n",
    "            print('desc',batch_1['desc'])\n",
    "\n",
    "            \n",
    "            # with autocast:\n",
    "            outputs = model(**batch_1)\n",
    "            r_loss = loss_fn(outputs, mix.long())\n",
    "            grad_1, lr_1 = trainer.step(r_loss, model.parameters())\n",
    "\n",
    "            step += 1\n",
    "            n_element += 1\n",
    "            if rank == 0:\n",
    "                writer.add_scalar(\"r_loss\", r_loss.item(), step)\n",
    "                writer.add_scalar(\"grad_1\", grad_1, step)\n",
    "                writer.add_scalar(\"lr_1\", lr_1, step)\n",
    "\n",
    "            mean_loss += r_loss.item()\n",
    "\n",
    "        mean_loss = mean_loss / n_element\n",
    "        if rank == 0:\n",
    "            with torch.no_grad():\n",
    "                writer.add_scalar('train/mean_loss', mean_loss, step)\n",
    "                model.save_weights(os.path.join(model_dir, f\"diff_{e}_end.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /l/users/fathinah.izzati/datasets/test.lst\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/l/users/fathinah.izzati/datasets/test.lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset, dataloader \u001b[38;5;241m=\u001b[39m  \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/l/users/fathinah.izzati/datasets/test.lst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprob-based\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleNamespace\n\u001b[1;32m      4\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     15\u001b[0m }\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(rid, dataset_path, sampling_strategy, sampling_prob)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset\u001b[39m(rid, dataset_path, sampling_strategy, sampling_prob):\n\u001b[0;32m---> 38\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrainCfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     46\u001b[0m         dataset,\n\u001b[1;32m     47\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mTrainCfg\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m         pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m         drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset, dataloader\n",
      "File \u001b[0;32m/l/users/fathinah.izzati/coco-mulla-repo/coco_mulla/data_loader/dataset_sampler.py:41\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, path_lst, cfg, rid, sampling_prob, sampling_strategy, inference)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(path_lst):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i,path)\n\u001b[0;32m---> 41\u001b[0m     data, data_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data, data_index)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[0;32m/l/users/fathinah.izzati/coco-mulla-repo/coco_mulla/data_loader/dataset_sampler.py:7\u001b[0m, in \u001b[0;36mload_data_from_path\u001b[0;34m(path, idx, sec)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_from_path\u001b[39m(path, idx, sec):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/l/users/fathinah.izzati/datasets/test.lst'"
     ]
    }
   ],
   "source": [
    "dataset, dataloader =  get_dataset(1, '/l/users/fathinah.izzati/datasets/test.lst', 'prob-based', None)\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = {\n",
    "    \"num_layers\": 48,\n",
    "    \"latent_dim\": 768,\n",
    "    \"experiment_folder\": \"/l/users/fathinah.izzati/coco-mulla-repo/expe\",\n",
    "    \"experiment_name\": \"experiment_1\",\n",
    "    \"prompt_path\": \"/l/users/fathinah.izzati/coco-mulla-repo/demo/input/let_it_be.prompt.txt\",\n",
    "    'sampling_strategy':'prob-based',\n",
    "    'sampling_prob_a':0.5,\n",
    "    'sampling_prob_b':0.5,\n",
    "    \"dataset\": None,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "args = SimpleNamespace(**args)\n",
    "model = CoCoMulla(TrainCfg.sample_sec, num_layers=args.num_layers, latent_dim=args.latent_dim).to(device)\n",
    "model.set_training()\n",
    "# model = DDP(model, [0])\\\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "train(1, model, dataset, dataloader, device,  '/l/users/fathinah.izzati/coco-mulla-repo/demo',args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
